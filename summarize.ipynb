{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize CLI - Notebook\n",
    "\n",
    "If you prefer working in a notebook environment rather than a command line tool, this is for you! You can run each of the steps (deployment, querying, removing resources) in its associated cell below. As always, please remember to run the cell which deletes your resources (final cell in the notebook) to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\"HF_MODEL_ID\": \"google/pegasus-xsum\", \"HF_TASK\": \"summarization\"}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version=\"4.17.0\",\n",
    "    pytorch_version=\"1.10.2\",\n",
    "    py_version=\"py38\",\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying model to SageMaker. this may take a few minutes...\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "print(\"deploying model to SageMaker. this may take a few minutes...\")\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,  # number of instances\n",
    "    instance_type=\"ml.m5.xlarge\",  # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you have a question about this or any other article on this website, please use the form below.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"replace this with the text you want to summarize.\"\n",
    "\n",
    "predictor.predict({\"inputs\": text})[0].get(\"summary_text\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "One or more models cannot be deleted, please retry. \nFailed models: huggingface-pytorch-inference-2023-02-26-22-17-21-612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# delete model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictor\u001b[39m.\u001b[39;49mdelete_model()\n\u001b[1;32m      4\u001b[0m \u001b[39m# delete endpoint - also deletes the endpoint configuration\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictor\u001b[39m.\u001b[39mdelete_endpoint()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sagemaker/predictor.py:348\u001b[0m, in \u001b[0;36mPredictor.delete_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m         failed_models\u001b[39m.\u001b[39mappend(model_name)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m request_failed:\n\u001b[0;32m--> 348\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    349\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOne or more models cannot be deleted, please retry. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed models: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed_models))\n\u001b[1;32m    351\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: One or more models cannot be deleted, please retry. \nFailed models: huggingface-pytorch-inference-2023-02-26-22-17-21-612"
     ]
    }
   ],
   "source": [
    "# delete model\n",
    "predictor.delete_model()\n",
    "\n",
    "# delete endpoint - also deletes the endpoint configuration\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
